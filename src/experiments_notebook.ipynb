{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "from configs import ConfigPath\n",
    "from data_preprocessing.text_splitter import TextSplitter\n",
    "from utils.utils import read_json_file\n",
    "from llms.embedding_model import EmbeddingModel\n",
    "from knowledge_graph.loader import GraphLoader\n",
    "from knowledge_graph.crud import GraphCrud\n",
    "from configs.config import ConfigEnv\n",
    "from knowledge_graph.connection import Neo4jConnection\n",
    "from llms.llm import LLM\n",
    "from retrieval.tools.vector_search_tool import VectorSearchTool\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-06 22:55:14,407 [DEBUG] embedding_model - CUDA is available, using GPU\n",
      "2025-03-06 22:55:33,462 [DEBUG] embedding_model - Embedding model initialized: neuml/pubmedbert-base-embeddings\n"
     ]
    }
   ],
   "source": [
    "# models\n",
    "embedding_model = EmbeddingModel()\n",
    "llm = LLM.initialize_model(provider=\"google\", model_name=\"gemini-2.0-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-06 22:55:37,668 [DEBUG] connection - Connection successful!\n"
     ]
    }
   ],
   "source": [
    "# data\n",
    "data = read_json_file(file_path=os.path.join(ConfigPath.RAW_DATA_DIR, \"pqa_labeled.json\"))  \n",
    "\n",
    "# modules\n",
    "# text_splitter = TextSplitter()\n",
    "neo4j_connection = Neo4jConnection(uri=ConfigEnv.NEO4J_URI, \n",
    "                 user=ConfigEnv.NEO4J_USER,\n",
    "                 password=ConfigEnv.NEO4J_PASSWORD,\n",
    "                 database=ConfigEnv.NEO4J_DB)\n",
    "# crud = GraphCrud(neo4j_connection=neo4j_connection)\n",
    "# graph_loader = GraphLoader(text_splitter=text_splitter,\n",
    "#                            embedding_model=embedding_model,\n",
    "#                            crud=crud,\n",
    "#                            data=data)\n",
    "\n",
    "vector_search_tool = VectorSearchTool(\n",
    "    llm=llm,\n",
    "    embedding_model=embedding_model,\n",
    "    neo4j_connection=neo4j_connection,\n",
    "    return_direct=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    }
   ],
   "source": [
    "# answer = vector_search_tool.invoke(\"Can tailored interventions increase mammography use among HMO women?\")\n",
    "# print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-06 22:55:49,097 [INFO] evaluation - Generating results...\n",
      "Generating results...:   6%|â–‹         | 64/1000 [05:07<1:16:50,  4.93s/it]"
     ]
    }
   ],
   "source": [
    "from evalution.evaluation import Evaluator\n",
    "\n",
    "evaluator = Evaluator(ground_truth_data=data, retriever=vector_search_tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-06 22:04:24,015 [INFO] evaluation - Computing metrics...\n",
      "2025-03-06 22:04:24,020 [INFO] evaluation - Accuracy: 0.5000\n",
      "2025-03-06 22:04:24,020 [INFO] evaluation - Precision: 0.5000\n",
      "2025-03-06 22:04:24,022 [INFO] evaluation - Recall: 1.0000\n",
      "2025-03-06 22:04:24,023 [INFO] evaluation - F1: 0.6667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.5, 'precision': 0.5, 'recall': 1.0, 'f1': 0.6666666666666666}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.compute_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hey there! How can I help you today?', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-7c4fea5e-cdb8-4395-9fd1-6f27607d40e4-0', usage_metadata={'input_tokens': 1, 'output_tokens': 11, 'total_tokens': 12, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"hey\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
