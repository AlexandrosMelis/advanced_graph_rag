{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from utils.utils import read_json_file, save_json_file\n",
    "from llms.embedding_model import EmbeddingModel\n",
    "from configs.config import ConfigEnv, ConfigPath\n",
    "from knowledge_graph.connection import Neo4jConnection\n",
    "from llms.llm import ChatModel\n",
    "from data_collection.reader import BioASQDataReader\n",
    "from tqdm import tqdm\n",
    "from langchain_neo4j import Neo4jVector\n",
    "from retrieval_techniques.similarity_search import SimilaritySearchRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-10 21:03:20,785 [DEBUG] embedding_model - CUDA is available, using GPU\n",
      "2025-04-10 21:03:40,795 [DEBUG] embedding_model - Embedding model initialized: neuml/pubmedbert-base-embeddings\n",
      "2025-04-10 21:03:40,810 [DEBUG] llm - Initialized model gemini-2.0-flash-lite\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using database: bioasq1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-10 21:03:44,952 [DEBUG] connection - Connection successful!\n",
      "2025-04-10 21:03:45,016 [INFO] reader - Limiting the number of rows to 3...\n",
      "2025-04-10 21:03:45,018 [INFO] reader - Data file loaded with shape: (3, 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data length: 3\n"
     ]
    }
   ],
   "source": [
    "# models\n",
    "embedding_model = EmbeddingModel()\n",
    "\n",
    "llm = ChatModel(provider=\"google\", model_name=\"gemini-2.0-flash-lite\").initialize_model()\n",
    "\n",
    "# neo4j connection\n",
    "neo4j_connection = Neo4jConnection(uri=ConfigEnv.NEO4J_URI, \n",
    "                 user=ConfigEnv.NEO4J_USER,\n",
    "                 password=ConfigEnv.NEO4J_PASSWORD,\n",
    "                 database=ConfigEnv.NEO4J_DB)\n",
    "\n",
    "# retriever\n",
    "similarity_retriever = SimilaritySearchRetriever(\n",
    "    llm=llm,\n",
    "    embedding_model=embedding_model,\n",
    "    neo4j_connection=neo4j_connection,\n",
    ")\n",
    "\n",
    "# data\n",
    "data_path = os.path.join(ConfigPath.RAW_DATA_DIR, \"bioasq_train.parquet\")\n",
    "reader = BioASQDataReader(samples_limit=3)\n",
    "data = reader.read_parquet_file(file_path=data_path) \n",
    "print(f\"Data length: {len(data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centrality type: degree\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['21415143',\n",
       " '10566200',\n",
       " '17160166',\n",
       " '20810577',\n",
       " '22009156',\n",
       " '17205086',\n",
       " '23786024',\n",
       " '11932302',\n",
       " '18290900',\n",
       " '12800543']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_retriever = SimilaritySearchRetriever(llm=llm, embedding_model=embedding_model, neo4j_connection=neo4j_connection)\n",
    "results = similarity_retriever.perform_retrieval(retrieval_type=\"mesh_centrality_contexts\",\n",
    "                                                 query=\"What is the aim of iodine prophylaxis?\",\n",
    "                                                 k=10, \n",
    "                                                 centrality_type=\"degree\")\n",
    "pmids_found = [r['pmid'] for r in results]\n",
    "pmids_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "index_name = \"context_index\"  # default index name\n",
    "\n",
    "existing_graph = Neo4jVector.from_existing_graph(\n",
    "    embedding=embedding_model,\n",
    "    url=ConfigEnv.NEO4J_URI,\n",
    "    username=ConfigEnv.NEO4J_USER,\n",
    "    password=ConfigEnv.NEO4J_PASSWORD,\n",
    "    index_name=\"context_index\",\n",
    "    node_label=\"CONTEXT\",\n",
    "    # text_node_properties=[\"text_content\"],\n",
    "    embedding_node_property=\"embedding\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_graph.search(\"Utilization behavior (UB) consists of reaching out and using objects in the environment in an automatic mann\", search_type=\"mmr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def run_retriever(benchmark_data: list, retriever) -> dict:\n",
    "    results = {}\n",
    "    for sample in tqdm(benchmark_data, desc=\"Executing retriever...\"):\n",
    "        sample_id = sample.get('id')\n",
    "        question = sample.get('question')\n",
    "        retrieved_data = retriever.invoke(question)\n",
    "        results[sample_id] = retrieved_data\n",
    "    return results\n",
    "\n",
    "results = run_retriever(benchmark_data=data, retriever=vector_search_tool)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "metrics, new_evaluator = run_evaluation_on_retrieved_chunks(\n",
    "    retrieval_results=results,\n",
    "    benchmark_data=data\n",
    ")\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAGAS METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_search_tool = VectorSimilaritySearchTool(\n",
    "        llm=llm,\n",
    "        embedding_model=embedding_model,\n",
    "        neo4j_connection=neo4j_connection,\n",
    "        return_direct=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = vector_search_tool.invoke(\"What is the implication of histone lysine methylation in medulloblastoma?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contexts = [sample['content'] for sample in results['context']]\n",
    "contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.llms import LangchainLLMWrapper\n",
    "\n",
    "llm = ChatModel(provider=\"google\", model_name=\"gemini-2.0-flash-lite\").initialize_model()\n",
    "evaluator_llm = LangchainLLMWrapper(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from ragas.dataset_schema import SingleTurnSample\n",
    "from ragas.metrics import ContextRelevance\n",
    "\n",
    "sample = SingleTurnSample(\n",
    "    user_input=\"What is the implication of histone lysine methylation in medulloblastoma?\",\n",
    "    retrieved_contexts=contexts\n",
    ")\n",
    "\n",
    "scorer = ContextRelevance(llm=evaluator_llm)\n",
    "score = await scorer.single_turn_ascore(sample)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas import EvaluationDataset\n",
    "\n",
    "\n",
    "dataset = []\n",
    "dataset.append(\n",
    "        {\n",
    "            \"id\": 1,\n",
    "            \"user_input\": \"What is the implication of histone lysine methylation in medulloblastoma?\",\n",
    "            \"retrieved_contexts\": contexts,\n",
    "            \"response\": \"Histone lysine methylation, particularly at H3K9, is implicated in the pathogenesis of medulloblastoma. Copy number aberrations in genes involved in writing, reading, removing, and blocking histone lysine methylation suggest that defective control of the histone code contributes to the development of this cancer. Additionally, the study found that restoration of expression of genes controlling H3K9 methylation greatly diminishes proliferation of medulloblastoma in vitro.\",\n",
    "            \"reference\": \"Aberrant patterns of H3K4, H3K9, and H3K27 histone lysine methylation were shown to result in histone code alterations, which induce changes in gene expression, and affect the proliferation rate of cells in medulloblastoma.\", # expected response\n",
    "        }\n",
    "    )\n",
    "evaluation_dataset = EvaluationDataset.from_list(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas import evaluate\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "from ragas.metrics import LLMContextPrecisionWithReference, ContextRecall, ResponseRelevancy, FactualCorrectness\n",
    "\n",
    "evaluator_llm = LangchainLLMWrapper(llm)\n",
    "evaluator_embedding = LangchainEmbeddingsWrapper(embedding_model)\n",
    "\n",
    "context_precision = LLMContextPrecisionWithReference()\n",
    "context_recall = ContextRecall()\n",
    "response_relevancy = ResponseRelevancy()\n",
    "factual_correctness = FactualCorrectness()\n",
    "\n",
    "result = evaluate(\n",
    "    dataset=evaluation_dataset,\n",
    "    metrics=[context_precision, context_recall, response_relevancy, factual_correctness],\n",
    "    llm=evaluator_llm,\n",
    "    embeddings=evaluator_embedding\n",
    ")\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read paquet data\n",
    "import os\n",
    "import pandas as pd\n",
    "from configs.config import ConfigPath\n",
    "\n",
    "from data_collection.reader import BioASQDataReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asq_reader = BioASQDataReader()\n",
    "data = asq_reader.read_parquet_file(file_path=os.path.join(ConfigPath.RAW_DATA_DIR, \"bioasq_train.parquet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in data:\n",
    "    if 20007090 in sample[\"relevant_passage_ids\"]:\n",
    "        print(sample)\n",
    "        print(data.index(sample))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asq_reader.get_data_to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_collection.fetcher import PubMedArticleFetcher\n",
    "\n",
    "fetcher = PubMedArticleFetcher()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = fetcher.fetch_articles(pmids=['20007090'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
