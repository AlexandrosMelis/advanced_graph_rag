{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "from configs import ConfigPath\n",
    "from data_preprocessing.text_splitter import TextSplitter\n",
    "from utils.utils import read_json_file\n",
    "from llms.embedding_model import EmbeddingModel\n",
    "from knowledge_graph.loader import GraphLoader\n",
    "from knowledge_graph.crud import GraphCrud\n",
    "from configs.config import ConfigEnv\n",
    "from knowledge_graph.connection import Neo4jConnection\n",
    "from llms.llm import ChatModel\n",
    "from retrieval.tools.vector_search_tool import VectorSearchTool\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-07 00:41:29,584 [DEBUG] embedding_model - CUDA is available, using GPU\n",
      "2025-03-07 00:41:51,511 [DEBUG] embedding_model - Embedding model initialized: neuml/pubmedbert-base-embeddings\n"
     ]
    }
   ],
   "source": [
    "# models\n",
    "embedding_model = EmbeddingModel()\n",
    "chat_model = ChatModel(provider=\"google\", model_name=\"gemini-2.0-pro-exp-02-05\")\n",
    "llm = chat_model.llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-06 22:55:37,668 [DEBUG] connection - Connection successful!\n"
     ]
    }
   ],
   "source": [
    "# data\n",
    "data = read_json_file(file_path=os.path.join(ConfigPath.RAW_DATA_DIR, \"pqa_labeled.json\"))  \n",
    "\n",
    "# modules\n",
    "# text_splitter = TextSplitter()\n",
    "neo4j_connection = Neo4jConnection(uri=ConfigEnv.NEO4J_URI, \n",
    "                 user=ConfigEnv.NEO4J_USER,\n",
    "                 password=ConfigEnv.NEO4J_PASSWORD,\n",
    "                 database=ConfigEnv.NEO4J_DB)\n",
    "# crud = GraphCrud(neo4j_connection=neo4j_connection)\n",
    "# graph_loader = GraphLoader(text_splitter=text_splitter,\n",
    "#                            embedding_model=embedding_model,\n",
    "#                            crud=crud,\n",
    "#                            data=data)\n",
    "\n",
    "vector_search_tool = VectorSearchTool(\n",
    "    llm=llm,\n",
    "    embedding_model=embedding_model,\n",
    "    neo4j_connection=neo4j_connection,\n",
    "    return_direct=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    }
   ],
   "source": [
    "# answer = vector_search_tool.invoke(\"Can tailored interventions increase mammography use among HMO women?\")\n",
    "# print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-06 22:55:49,097 [INFO] evaluation - Generating results...\n",
      "Generating results...: 100%|██████████| 1000/1000 [1:19:54<00:00,  4.79s/it]\n",
      "2025-03-07 00:15:43,448 [INFO] evaluation - Generated 1000 results.\n",
      "2025-03-07 00:15:43,493 [INFO] evaluation - Results saved to C:\\Users\\melis\\Desktop\\Projects\\python_projects\\thesis\\advanced_graph_rag\\data\\results\\evaluation_results_20250307_001543.json\n"
     ]
    }
   ],
   "source": [
    "from evalution.evaluation import Evaluator\n",
    "\n",
    "evaluator = Evaluator(ground_truth_data=data, retriever=vector_search_tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-07 00:15:50,392 [INFO] evaluation - Computing metrics...\n",
      "2025-03-07 00:15:50,508 [INFO] evaluation - Accuracy: 0.6780\n",
      "2025-03-07 00:15:50,511 [INFO] evaluation - Precision: 0.6423\n",
      "2025-03-07 00:15:50,512 [INFO] evaluation - Recall: 0.9402\n",
      "2025-03-07 00:15:50,514 [INFO] evaluation - F1: 0.7632\n",
      "2025-03-07 00:15:50,517 [INFO] evaluation - Results saved to C:\\Users\\melis\\Desktop\\Projects\\python_projects\\thesis\\advanced_graph_rag\\data\\metrics\\answering_metrics_20250307_001550.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.678,\n",
       " 'precision': 0.6423267326732673,\n",
       " 'recall': 0.9402173913043478,\n",
       " 'f1': 0.763235294117647}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.compute_metrics()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
